# Heart Disease Classification - Complete Guide

## ğŸ“‹ Project Overview

This project implements a complete ML pipeline for predicting heart disease risk using:
- **Data Processing**: Cleaning & standardization
- **ML Models**: Logistic Regression & SVM
- **Backend API**: FastAPI for predictions
- **Frontend**: Streamlit for interactive testing

---

## ğŸ¯ Task Breakdown

### 1. **Data Loading & Exploration** (`1_preprocessing.py`)
- âœ“ Loads `heart(in).csv` dataset
- âœ“ Displays dataset shape and structure
- âœ“ Identifies features and target variable

**Output**: Dataset overview
```
Dataset shape: (1026, 14)
- 13 features (age, sex, cp, trestbps, etc.)
- 1 target variable (presence of heart disease)
```

---

### 2. **Data Cleaning** (`1_preprocessing.py`)
- âœ“ Removes rows with missing values using `.dropna()`
- âœ“ Removes duplicate rows using `.drop_duplicates()`
- âœ“ Verifies data quality

**Process**:
```python
# Remove missing values
df_clean = df.dropna()

# Remove duplicates
df_clean = df_clean.drop_duplicates()
```

---

### 3. **Feature Standardization** (`1_preprocessing.py`)
- âœ“ Uses `StandardScaler` to normalize numerical columns
- âœ“ Formula: (value - mean) / std_dev
- âœ“ Essential for SVM and Logistic Regression

**Process**:
```python
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
```

**Benefits**:
- Centers data around 0 with std dev = 1
- Improves model convergence
- Makes coefficients comparable

---

### 4. **Model Training** (`2_train_model.py`)

#### **Logistic Regression**
- Binary classification algorithm
- Output: Probability between 0-1
- Fast training and inference
- Good baseline model

#### **SVM (Support Vector Machine)**
- Finds optimal hyperplane to separate classes
- RBF kernel captures non-linear patterns
- Robust to outliers
- Better for complex decision boundaries

**Training Process**:
```python
# Split data
X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Train models
lr_model = LogisticRegression(max_iter=1000)
lr_model.fit(X_train, y_train)

svm_model = SVC(kernel='rbf', probability=True)
svm_model.fit(X_train, y_train)
```

**Evaluation Metrics**:
- **Accuracy**: Overall correctness
- **Precision**: True positives / (True positives + False positives)
- **Recall**: True positives / (True positives + False negatives)
- **F1-Score**: Harmonic mean of precision & recall
- **ROC-AUC**: Area under receiver operating characteristic curve

---

### 5. **Model Persistence** (`2_train_model.py`)
- âœ“ Saves best performing model to `models/best_model.pkl`
- âœ“ Saves scaler to `data/scaler.pkl`
- âœ“ Saves feature names to `data/feature_names.pkl`
- âœ“ All models use pickle serialization

**Files Created**:
```
models/
â”œâ”€â”€ logistic_regression.pkl
â”œâ”€â”€ svm_model.pkl
â”œâ”€â”€ best_model.pkl
â””â”€â”€ best_model_name.txt

data/
â”œâ”€â”€ X_train.csv
â”œâ”€â”€ X_test.csv
â”œâ”€â”€ y_train.csv
â”œâ”€â”€ y_test.csv
â”œâ”€â”€ scaler.pkl
â””â”€â”€ feature_names.pkl
```

---

### 6. **FastAPI Backend** (`3_fastapi_app.py`)

#### **Endpoints**

**1. Health Check**
```
GET /
GET /health
```
Returns API status and model information.

**2. Single Prediction**
```
POST /predict
```
Input: Patient data (13 features)
```json
{
  "age": 52,
  "sex": 1,
  "cp": 0,
  "trestbps": 125,
  "chol": 212,
  "fbs": 0,
  "restecg": 1,
  "thalach": 168,
  "exang": 0,
  "oldpeak": 1,
  "slope": 2,
  "ca": 2,
  "thal": 3
}
```

Output:
```json
{
  "prediction": 0,
  "confidence": 0.85,
  "model": "Logistic Regression",
  "risk_level": "moderate"
}
```

**3. Batch Prediction**
```
POST /predict-batch
```
Input: Array of patients
Output: Array of predictions

**4. Model Information**
```
GET /model-info
```
Returns model details and features.

#### **Key Features**
- âœ“ Data validation using Pydantic models
- âœ“ Automatic scaling using saved scaler
- âœ“ Error handling and HTTP exceptions
- âœ“ Confidence scoring
- âœ“ Risk level classification
- âœ“ Auto-generated API documentation at `/docs`

---

### 7. **Streamlit Frontend** (`4_streamlit_app.py`)

#### **Three Modes**

**1. Single Prediction**
- Interactive form for patient data
- Sliders for numerical inputs
- Dropdowns for categorical inputs
- Real-time prediction with confidence display

**2. Batch Upload**
- Upload CSV files with multiple patients
- Bulk predictions
- Download results as CSV

**3. Sample Test**
- Pre-configured sample patients
- Test with predefined cases
- Quick demonstration

#### **Features**
- âœ“ Beautiful UI with custom styling
- âœ“ Real-time API connectivity check
- âœ“ Risk level visualization (ğŸŸ¢ğŸŸ¡ğŸ”´)
- âœ“ Responsive design
- âœ“ Export predictions to CSV

---

## ğŸš€ Installation & Setup

### **Step 1: Install Dependencies**
```bash
cd /workspaces/AIML_Task
pip install -r requirements.txt
```

### **Step 2: Run Preprocessing & Training**
```bash
python 1_preprocessing.py
python 2_train_model.py
```

This will create:
- Preprocessed data files in `data/`
- Trained models in `models/`
- Visualizations in `plots/`

### **Step 3: Start FastAPI Server** (Terminal 1)
```bash
python 3_fastapi_app.py
```

The API will be available at:
- Application: `http://localhost:8000`
- Interactive docs: `http://localhost:8000/docs`
- ReDoc: `http://localhost:8000/redoc`

### **Step 4: Start Streamlit Frontend** (Terminal 2)
```bash
streamlit run 4_streamlit_app.py
```

Access Streamlit at: `http://localhost:8501`

### **Quick Start Script**
```bash
chmod +x setup.sh
./setup.sh
```

Then run in separate terminals:
```bash
python 3_fastapi_app.py
streamlit run 4_streamlit_app.py
```

---

## ğŸ“Š Data Features Explanation

| Feature | Range | Description |
|---------|-------|-------------|
| age | 29-77 | Patient age in years |
| sex | 0,1 | 0=female, 1=male |
| cp | 0-3 | Chest pain type (0=typical, 1=atypical, 2=non-anginal, 3=asymptomatic) |
| trestbps | 90-200 | Resting blood pressure (mmHg) |
| chol | 126-564 | Serum cholesterol (mg/dl) |
| fbs | 0,1 | Fasting blood sugar > 120 mg/dl (0=no, 1=yes) |
| restecg | 0-2 | Resting ECG results |
| thalach | 60-202 | Maximum heart rate achieved |
| exang | 0,1 | Exercise induced angina (0=no, 1=yes) |
| oldpeak | 0-6.2 | ST depression induced by exercise |
| slope | 0-2 | Slope of ST segment |
| ca | 0-4 | Number of major vessels (0-3) colored by fluoroscopy |
| thal | 0-3 | Thalassemia type |
| **target** | **0,1** | **0=no disease, 1=disease present** |

---

## ğŸ“ How Models Work

### **Logistic Regression**
```
Process:
1. Linear combination: z = wâ‚€ + wâ‚xâ‚ + wâ‚‚xâ‚‚ + ... + wâ‚â‚ƒxâ‚â‚ƒ
2. Sigmoid function: p = 1 / (1 + e^(-z))
3. Classification: if p > 0.5 â†’ disease (1), else â†’ no disease (0)

Advantages:
- Fast training
- Interpretable coefficients
- Good baseline
```

### **SVM with RBF Kernel**
```
Process:
1. Maps data to higher-dimensional space
2. Finds optimal hyperplane separating classes
3. Maximizes margin between classes
4. Uses RBF kernel for non-linear boundaries

Advantages:
- Handles non-linear patterns
- Robust to outliers
- Good generalization
```

---

## ğŸ“ˆ Example Workflow

### **1. Preprocessing**
```
Input: heart(in).csv (1026 rows, 14 columns)
   â†“
Remove missing values (dropna)
   â†“
Remove duplicates
   â†“
Standardize numerical features (StandardScaler)
   â†“
Split: 80% train (820 rows), 20% test (206 rows)
   â†“
Output: X_train, X_test, y_train, y_test + scaler
```

### **2. Model Training**
```
Input: Preprocessed data
   â†“
Train Logistic Regression Model
Train SVM Model
   â†“
Evaluate on test set
   â†“
Compare metrics
   â†“
Output: Best model saved + metrics/visualizations
```

### **3. API Usage**
```
User â†’ Streamlit UI
   â†“
Streamlit sends patient data to FastAPI
   â†“
FastAPI scales features using saved scaler
   â†“
Model makes prediction
   â†“
Returns: prediction + confidence + risk level
   â†“
Streamlit displays results
```

---

## ğŸ” Testing the API

### **Using FastAPI Docs** (Built-in UI)
1. Go to: `http://localhost:8000/docs`
2. Find the `/predict` endpoint
3. Click "Try it out"
4. Enter sample data
5. Click "Execute"

### **Using curl**
```bash
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "age": 52,
    "sex": 1,
    "cp": 0,
    "trestbps": 125,
    "chol": 212,
    "fbs": 0,
    "restecg": 1,
    "thalach": 168,
    "exang": 0,
    "oldpeak": 1,
    "slope": 2,
    "ca": 2,
    "thal": 3
  }'
```

### **Using Python**
```python
import requests

url = "http://localhost:8000/predict"
data = {
    "age": 52,
    "sex": 1,
    "cp": 0,
    "trestbps": 125,
    "chol": 212,
    "fbs": 0,
    "restecg": 1,
    "thalach": 168,
    "exang": 0,
    "oldpeak": 1,
    "slope": 2,
    "ca": 2,
    "thal": 3
}

response = requests.post(url, json=data)
print(response.json())
```

---

## ğŸ“Š Expected Output

### **Model Performance**
```
Logistic Regression:
- Accuracy:  0.85-0.90
- Precision: 0.82-0.88
- Recall:    0.80-0.88
- F1-Score:  0.81-0.87
- ROC-AUC:   0.88-0.93

SVM:
- Accuracy:  0.82-0.88
- Precision: 0.80-0.86
- Recall:    0.78-0.85
- F1-Score:  0.79-0.85
- ROC-AUC:   0.85-0.91
```

### **Prediction Output**
```json
{
  "prediction": 0,              // 0=No disease, 1=Disease present
  "confidence": 0.85,           // Probability (0-1)
  "model": "Logistic Regression",
  "risk_level": "moderate"      // low, moderate, or high
}
```

---

## ğŸ› Troubleshooting

### **Issue: API Connection Failed**
```
Solution: Ensure FastAPI server is running
python 3_fastapi_app.py
```

### **Issue: Module Not Found**
```
Solution: Install requirements
pip install -r requirements.txt
```

### **Issue: Port Already in Use**
```
Solution 1: Kill existing process
lsof -ti:8000 | xargs kill -9

Solution 2: Use different port
python 3_fastapi_app.py --port 8001
```

### **Issue: Scaler/Model Not Found**
```
Solution: Run preprocessing and training first
python 1_preprocessing.py
python 2_train_model.py
```

---

## ğŸ“ Project Structure

```
/workspaces/AIML_Task/
â”œâ”€â”€ heart(in).csv                 # Original dataset
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ setup.sh                      # Setup script
â”‚
â”œâ”€â”€ 1_preprocessing.py            # Data loading & cleaning
â”œâ”€â”€ 2_train_model.py              # Model training
â”œâ”€â”€ 3_fastapi_app.py              # FastAPI backend
â”œâ”€â”€ 4_streamlit_app.py            # Streamlit frontend
â”‚
â”œâ”€â”€ data/                         # Preprocessed data
â”‚   â”œâ”€â”€ X_train.csv
â”‚   â”œâ”€â”€ X_test.csv
â”‚   â”œâ”€â”€ y_train.csv
â”‚   â”œâ”€â”€ y_test.csv
â”‚   â”œâ”€â”€ scaler.pkl
â”‚   â””â”€â”€ feature_names.pkl
â”‚
â”œâ”€â”€ models/                       # Trained models
â”‚   â”œâ”€â”€ logistic_regression.pkl
â”‚   â”œâ”€â”€ svm_model.pkl
â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â””â”€â”€ best_model_name.txt
â”‚
â””â”€â”€ plots/                        # Visualizations
    â”œâ”€â”€ confusion_matrices.png
    â””â”€â”€ roc_curves.png
```

---

## âœ… Checklist - Step by Step

- [ ] **Step 1**: Install dependencies (`pip install -r requirements.txt`)
- [ ] **Step 2**: Run preprocessing (`python 1_preprocessing.py`)
- [ ] **Step 3**: Train models (`python 2_train_model.py`)
- [ ] **Step 4**: Start FastAPI (`python 3_fastapi_app.py`)
- [ ] **Step 5**: Start Streamlit (`streamlit run 4_streamlit_app.py`)
- [ ] **Step 6**: Test single prediction in Streamlit
- [ ] **Step 7**: Test batch upload
- [ ] **Step 8**: Test API directly using FastAPI docs (`/docs`)
- [ ] **Step 9**: Review model performance metrics
- [ ] **Step 10**: Verify visualizations in `plots/` directory

---

## ğŸ‰ Success Criteria

âœ“ Data successfully preprocessed and cleaned
âœ“ Models trained with good accuracy (>85%)
âœ“ FastAPI running with all endpoints working
âœ“ Streamlit UI displaying predictions correctly
âœ“ Predictions are consistent and reliable
âœ“ API documentation auto-generated
âœ“ Models and scalers properly saved
âœ“ Batch processing working correctly

---

## ğŸ“š References & Best Practices

**Data Preprocessing**:
- Handle missing values early
- Standardize before model training
- Use stratified split for imbalanced data
- Keep train-test split separate

**Model Selection**:
- Logistic Regression: Fast, interpretable
- SVM: Better for non-linear patterns
- Always compare multiple models

**API Design**:
- Use meaningful status codes
- Validate input data
- Return consistent response format
- Document all endpoints

**Frontend Development**:
- Keep UI simple and intuitive
- Provide multiple input methods
- Show confidence scores
- Allow batch processing

---

## ğŸ¤ Support

For issues or questions:
1. Check FastAPI logs (`http://localhost:8000/docs`)
2. Check Streamlit logs (terminal where you ran streamlit)
3. Verify all data files exist in `data/` and `models/`
4. Ensure all requirements are installed

---

**Happy Predicting! â¤ï¸**
